Tries:
* BERT model
* dropout 0.1-> 0.2
* checkpoint ensemble & exponential moving average prediction ensemble
* ?!
* swore words replace with fuck
* trunction words and mispelling words
* identity weights
* special words for hexie
* Add a contraction mapping
* Try a (weighted) average of embeddings instead of concatenating them
* cyclic learning rate (CLR)
useful kernals
* https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2
* https://www.kaggle.com/artgor/toxicity-eda-logreg-and-nn-interpretation
* https://www.kaggle.com/nz0722/simple-eda-text-preprocessing-jigsaw
* https://www.kaggle.com/gemartin/load-data-reduce-memory-usage
